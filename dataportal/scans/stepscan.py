from ..broker import DataBroker
from ..muxer import DataMuxer
from pandas import DataFrame
from warnings import warn


class _StepScanClass(object):
    # A singleton is instantiated in scans/__init__.py.
    # You probably do not want to instantiate this; use
    # scans.StepScan instead.
    "Use the DataBroker interface to obtain step scan data as a DataFrame."
    fill_events = True
    def __getitem__(self, val):
        warn("StepScan is deprecated and will be removed. Use get_table.")
        headers = DataBroker[val]
        return _step_scan_df(headers, self.fill_events)

    def find_headers(cls, **kwargs):
        """Given search criteria, find Headers describing runs.

        This function returns a list of dictionary-like objects encapsulating
        the metadata for a run -- start time, instruments uses, and so on.
        In addition to the Parameters below, advanced users can specifiy
        arbitrary queries that are passed through to mongodb.

        Parameters
        ----------
        start_time : time-like, optional
            Include Headers for runs started after this time. Valid
            "time-like" representations are:
                - float timestamps (seconds since 1970), such as time.time()
                - '2015'
                - '2015-01'
                - '2015-01-30'
                - '2015-03-30 03:00:00'
                - Python datetime objects, such as datetime.datetime.now()
        stop_time: time-like, optional
            Include Headers for runs started before this time. See
            `start_time` above for examples.
        beamline_id : str, optional
            String identifier for a specific beamline
        project : str, optional
            Project name
        owner : str, optional
            The username of the logged-in user when the scan was performed
        scan_id : int, optional
            Integer scan identifier
        uid : str, optional
            Globally unique id string provided to metadatastore
        _id : str or ObjectId, optional
            The unique id generated by mongo
        data_key : str, optional
            The alias (e.g., 'motor1') or PV identifier of data source

        Returns
        -------
        df : pandas.DataFrame
            a tabular representation of the data

        Examples
        --------
        >>> find_headers(start_time='2015-03-05', stop_time='2015-03-10')
        >>> find_headers(data_key='motor1')
        >>> find_headers(data_key='motor1', start_time='2015-03-05')
        """
        warn("StepScan is deprecated and will be removed. Use get_table.")
        headers = DataBroker(**kwargs)
        return _step_scan_df(headers, cls.fill_events)


def _step_scan_df(headers, fill_events):
    try:
        headers.items()
    except AttributeError:
        pass
    else:
        headers = [headers]
    if len(headers) == 0:
        return DataFrame()  # no results
    empty_error = (
        "The header {0} seems to have no event descriptors. "
        "Perhaps it was just created? If this is for an ongoing "
        "scan, please wait a moment.")
    if not headers[0]['descriptors']:
        raise ValueError(empty_error.format(repr(headers[0])))
    data_keys = headers[0]['descriptors'][0].data_keys.keys()
    for header in headers[1:]:
        if len(header['descriptors']) == 0:
            raise ValueError(empty_error.format(repr(header)))
        if len(header['descriptors']) > 1:
            raise ValueError("The header {0} has asynchronous Events; "
                             "it cannot be automatically treated as a "
                             "step scan.".format(repr(header)))
        if header['descriptors'][0].data_keys.keys() != data_keys:
            raise ValueError("Data keys for header {0} do not match "
                             "data keys for header {1}. All headers "
                             "must have the same data keys to be part "
                             "of the same StepScan.".format(
                                 repr(header), repr(headers[0])))
    events = DataBroker.fetch_events(headers, fill=fill_events)
    dm = DataMuxer.from_events(events)
    return dm.to_sparse_dataframe()
